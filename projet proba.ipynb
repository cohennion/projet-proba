{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet numérique : câbles sous-marins\n",
    "\n",
    "Corentin Hennion, Léa Mailhol \n",
    "\n",
    "## Questions théoiques\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{Question~1~:} $\n",
    "La loi forte des grands nombres nous autorise à estimer l'espérence conditionnelle par la moyenne empirique des simulations conditionnelles. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{Question~2~:}$\n",
    "On note $\\textbf{Z} = \\begin{pmatrix} Z(x_{1})=z(x_{1}) \\\\ ...\\\\...\\\\ Z(x_{N})=z(x_{N}) \\end{pmatrix} $ le vecteur correspond aux variables aléatoires liées aux points de discrétisation sans observation et $\\textbf{W} = \\begin{pmatrix} Z(x_{j_1}) \\\\ ...\\\\...\\\\ Z(x_{j_n})\\end{pmatrix} $ le vecteur correspondant aux variables aléatoires liées aux points d'observation. \n",
    "\n",
    "On cherche la loi de la variable aléatoire $Z|W = w$ où w est le vecteurs des valeurs prises aux points d'observations.\n",
    "\n",
    "On utilise la résulats du chapitre Probabilité 4 car les vecteurs $\\textbf{Z}$ et $\\textbf{W}$ sont des vecteurs gaussiens à densité.\n",
    "\n",
    "On obtient que la foncton de densité de la variable $Z|W = w$ est : \n",
    "\n",
    "$$f_{Z|W = w}(x) = \\frac{1}{(2\\pi)^{(N+1)/2}\\sqrt{det(C)}}exp(-\\frac{1}{2}(x-m_{Z|W=w})^t C^{-1}(x-m_{Z|W=w}))$$\n",
    "\n",
    "\n",
    "Avec $ m_{Z|W=w} = \\mu - C_{Z,W}C_W^{-1}(w-\\mu) $ et $ C = \\Sigma - C_{Z,W}C_w^{-1}C_{W,Z}$\n",
    "\n",
    "La matrice $C_{W,Z}$ a pour coefficients les $C_{W,Z}[i,k] = \\sigma_{ij_k} = |x_i - x_{j_k}|$\n",
    "\n",
    "Donc $Z|W = w$ est un vecteur gaussien à densité d'espérence $ m_{Z|W=w}$ et de matrice de convariance $C$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{Question~3~: }$ On prend $Y=(Y_1, ..., ..., Y_p)$ un vecteur de composantes gaussiennes indépendantes d'espérance nulle et de variance 1.\n",
    "\n",
    "Prenons $Z = m + RY$ avec $m$ vecteur de taille $p$ et $R$ une matrice de taille $p x p$. $Z$ est un vecteur gaussien par combinaison linéaire de vecteurs gaussiens.\n",
    "\n",
    "Alors chaque composante du vecteur $Z$ a pour espérance $E(Z_i) = m_i + E(\\sum_{j=0}^p R_{i,j}\\times Y_i) = m_i +\\sum_{j=0}^p R_{i,j}  E(Y_{j}) = m_{i}$\n",
    "\n",
    "Sa matrice de covariance est la matrice $C$ telle que $C_{i,j} = Cov(Z_i, Z_j) = E((Z_i - m_i)(Z_j - m_j)) = E(Z_iZ_j) - m^2 = \\sum_{k=0}^p\\sum_{l=0}^p r_{ik}r_{jl} E(Y_kY_l)$\n",
    "\n",
    "Or $E(Y_kY_l) = 0$ si $k\\ne l $ car les variables aléatoires sont indépendantes donc $C_{i,j} = \\sum_{k=0}^p r_{ik}r_{jk}$\n",
    "\n",
    "Au final, $Z$ est un vecteur gaussien d'espérance $m$ et de matrice de covariance est $C=RR^t$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\underline{ Question~4~:}$ L'algorithme de simulation conditionnelle va se dérouler comme suit :\n",
    "\n",
    "On cherche $P_Z$ et on utilise la formule des probabilités totales : $P_Z = \\sum_{w} P_{Z|W = w}P(W = w)$ avec Z et W définis en question 2.\n",
    "\n",
    "On connait les $P(W = w)$ et il nous faut calculer $P_{Z|W = w}$. Comme python ne peut simuler que des variables aléatoires gaussiennes d'espérance nulle et de variance 1, on doit se ramener à $Y_w$ qui est tel que $(Z|W = w) = (m + RY_w) $\n",
    "\n",
    "Pour cela on calcule $m$ avec l'expression donnée à la question 2 : $m = m_{Z|W=w}$\n",
    "Et pour $R$ on utilise la résolution python de la factorisation de Cholesky qui est définie par $C=RR^t$ avec $C$ la matrice de la question 2. \n",
    "\n",
    "On peut donc simuler la variable $Z|W = w$ en passant par $Y$ est on obtient finalement une simulation de $P_Z$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement de dépendances\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#Discrétisation\n",
    "A=0\n",
    "B=500\n",
    "N=101 #Nombre de points de discrétisation\n",
    "Delta = (B-A)/(N-1)\n",
    "discretization_indexes = np.arange(N)\n",
    "discretization = discretization_indexes*Delta\n",
    "#Paramètres du modèle\n",
    "mu=-5\n",
    "a = 50\n",
    "sigma2 = 12\n",
    "#Données\n",
    "observation_indexes = [0,20,40,60,80,100]\n",
    "depth = np.array([0,-4,-12.8,-1,-6.5,0])\n",
    "#Indices des composantes correspondant aux observations et aux componsantes non observées\n",
    "18\n",
    "unknown_indexes=list(set(discretization_indexes)-set(observation_indexes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{ Question~1~:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov(a , sigma2 , mat_dist) :\n",
    "    if type(mat_dist) == float or int :\n",
    "        return sigma2 * np.exp(-np.abs(mat_dist)/a)\n",
    "    else :\n",
    "        N , n = np.shape(mat_dist)\n",
    "        matcov = np.empty((N , n))\n",
    "        for i in range(N) :\n",
    "            for j in range(n) :\n",
    "                matcov[i, j] = sigma2 * np.exp(-np.abs(mat_dist[i, j])/a)\n",
    "        return matcov   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{ Question~2~:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.   5.  10. ... 490. 495. 500.]\n",
      " [  5.   0.   5. ... 485. 490. 495.]\n",
      " [ 10.   5.   0. ... 480. 485. 490.]\n",
      " ...\n",
      " [490. 485. 480. ...   0.   5.  10.]\n",
      " [495. 490. 485. ...   5.   0.   5.]\n",
      " [500. 495. 490. ...  10.   5.   0.]]\n"
     ]
    }
   ],
   "source": [
    "#la matrice de distance est définie par mat_dist[i,k] = |x[i] - x[k]|\n",
    "mat_dist = np.array( [[np.abs(discretization[i]-discretization[j]) for i in range (N)] for j in range(N)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{ Question~3~:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcov_Z = cov(a, sigma2, mat_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\underline{ Question~4~:}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
